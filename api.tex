%
% This document is available under the Creative Commons Attribution-ShareAlike
% License; additional terms may apply. See
%   * http://creativecommons.org/licenses/by-sa/3.0/
%   * http://creativecommons.org/licenses/by-sa/3.0/legalcode
%
% Created: 2012-03-13 00:09:51+01:00
% Main authors:
%     - Jérôme Pouiller <jezz@sysmic.org>
%

\part{L'API}

\begin{frame}
  \partpage
\end{frame}

\begin{frame}
  \tableofcontents[currentpart]
\end{frame}

\section{Les fonctions inspirés de la libc}

\begin{frame}{Fonctions standards de \file{string.h}}
  \begin{itemize} 
  \item Taille de chaines\c{strlen}, \c{strnlen}
  \item   Comparaisons:   \c{strcmp},   \c{strncmp},   \c{strcasecmp},
    \c{strncasecmp}, \c{ strnicmp}, \c{memcmp}, \c{strstarts}
  \item Recherches:  \c{strchr}, \c{strnchr}, \c{memchr}, \c{memscan},
    \c{strrchr},  \c{memchr_inv}, c{strspn},  \c{strcpsn}, \c{strstr},
    \c{strnstr}, \c{strpbrk}
  \item  Copies:   \c{strcpy},  \c{strncpy},  \c{memcpy},  \c{strcat},
    \c{strncat}, \c{strsep}
  \item \c{strlcpy}  et \c{strlcat} (De  meilleures implémentations de
    \c{strncat} et \c{strncpy}). Toujours utiliser ces fonctions.
  \item \c{skip_spaces},  \c{strim}, \c{strstrip}: Supprime  les blanc
    en début et fin de chaine
  \end{itemize}
\end{frame}

\begin{frame}{Fonctions standards de \file{string.h}}
  \begin{itemize} 
  \item  Convertions   de  nombres  et   de  booléens:  \c{strtobool},
    \lstinline+kstrto\{int,uint,l,ul\}+
    \lstinline+kstrto\{s64,u64,s32,u32,s16,u16,s8,u8\}+
    \lstinline+kstrto\{s64,u64,s32,u32,s16,u16,s8,u8\}_from_user+
    (existe aussi préfixé avec \c{simple_}, mais destiné à mourrir)
  \item   Duplication  avec   allocation:   \c{kmemdup},  \c{kstrdup},
    \c{kstrndup},  \c{memdup_user},   \c{strndup_user}  (nous  verrons
    l'argument \c{gfp} un peu plus loin)
  \item Formatage: \c{sprintf}, \c{snprintf}, \c{sscanf}
  \item  Utilitaire  sur  les  nombres:  \c{max},  \c{max3},  \c{min},
    \c{min3}, \c{clamp}, \c{swap}
  \item   Notez  que   beaucoup   de  ces   fonctions  possèdent   des
    implémentations  générique   mais  peuvent  être   surchargée  par
    architecture
  \item Référence: \file{linux/string.h} \file{linux/kernel.h}
  \end{itemize}
\end{frame} 

\section{Accéder au E/S}

\begin{frame}[fragile=singleslide]{Au sujet des accès aux E/S}
  La méthode d'accès dépend de l'architecture:
  \begin{itemize} 
  \item \emph{Memory Mapped Input  Output (MMIO)}: Registres mappés en
    mémoire.  Il suffit  de lire et écrire à  une adresse particulière
    pour écrire dans les registres du périphérique. La méthode la plus
    répandue
  \item \emph{Port  Input Output  (PIO)}: Registres accessible  par un
    bus   dédié.    Instructions   assembleurs  spécifiques   (\c{in},
    \c{out}).  Cas notable de l'architecture x86.
  \end{itemize}

  On  déclare rarement  les  adresses des  péiphéirque  en absolu.  On
  préfèrera définir les offsets à partir d'une base:
  \begin{lstlisting}
outb(base_device + REGISTER, 1);
  \end{lstlisting} 
  ou 
  \begin{lstlisting}
writeb(base_device->register, 1);
  \end{lstlisting} 
\end{frame}

\begin{frame}[fragile=singleslide]{Fonctionnement en PIO}
  \begin{itemize} 
  \item On doit  d'abord informer le noyau que  l'on utilise une plage
    de ports avec
    \begin{lstlisting} 
struct ressource *request_region(unsigned long start, unsigned long len, char *name);
void release_region(unsigned long start, unsigned long len);
    \end{lstlisting} 
  \item Référence: \c{linux/ioport.h}
  \item  Permet d'éviter que  deux drivers  essayent de  referencer la
    même plage de ports.
  \item  Il  est  possible  d'avoir  des  information  sur  les  ports
    actuellement utilisés en lisant le fichiers \file{/proc/ioports}
  \item Une fois réservé, il est possible de lire/écrire sur les ports
    avec :
\begin{lstlisting} 
u\{8,16,32\} in\{b,w,l\}(int port);
void out\{b,w,l\}(u\{8,16,32\} value, int port);
\end{lstlisting} 
  \item Ces  fonction s'occuppe  de convertir les  donnée dans  le bon
    endian
  \item Référence: \c{asm/io.h}
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{Fonctionnement en MMIO}
  \begin{itemize} 
  \item Il existe des fonctions identique pour les MMIO.
    \begin{lstlisting} 
struct ressource *request_mem_region(unsigned long start, unsigned long len, char *name)
void release_mem_region(unsigned long start, unsigned long len)
    \end{lstlisting} 
  \item  Il est possible  de voir  le mapping  actuel dans  le fichier
    \file{/proc/iomem}
  \item Il  est ensuite nécessaire de  faire appel au  MMU pour mapper
    les IO dans l'espace d'adressage du noyau
    \begin{lstlisting} 
void *ioremap(unsigned long phys_add, unsigned long size)
void iounmap(unsigned long phys_addr)
    \end{lstlisting}  
  \item Ces fonctions s'occuppent de la cohérence avec le cache.
\end{itemize} 
\end{frame}

\begin{frame}[fragile=singleslide]{Fonctionnement en MMIO}
  \begin{itemize} 
\item  Sur les  architectures  simples, il  possible de  directement
    déréférencer le résultat de  \c{ioremap}.  Il existe néanmoins des
    fonctions apportant  une couche d'abstraction  (barrières mémoire,
    etc...).
    \begin{lstlisting}  
u{8,16,32,64} read{b,w,l,q}(void *addr)
void write{b,w,l,q}(u{8,16,32,64}, void *addr)
    \end{lstlisting} 
  \item  Vous devez  utilisez  ces  fonctions: les  addr  ne sont  pas
    volatiles, write et  read s'occuppe de placer des  barrières et ou
    d'avoir des accès  ``volatiles'', il peut y avoir  des problème de
    SMP  ou   de  préemption  gérer  par  write   et  read,  certaines
    architecture e  support pas  l'acces direct à  la mémoire,  il est
    plus facile pour sparse de détecter des erreur
  \item Cas notable des accès PCI (little endian obligatoire)
  \end{itemize} 
\end{frame} 


\begin{frame}[fragile=singleslide]{Accèder aux IO en userspace}
  \begin{itemize} 
  \item  Le   device  \c{/dev/mem}  est  un   fichier  fichier  device
    permettant d'accèder aux addresses physiques.
  \item Il est possible d'utiliser \c{mmap} sur ce fichier et d'écrire
    aux addresses occuppées par des périphériques
  \item Sur les architecture utilisant PIO, il est possible de demande
    au  noyau  de  laisser   un  processus  utilisateur  utiliser  les
    instruction  assembleurs  \c{out*} et  \c{in*}  pour qu'il  puisse
    accèder aux périphérique avec \c{ioperm} et \c{iopl}.
  \item C'est  ainsi que fonctionne les serveurx  graphques XFree86 ou
    xorg
  \end{itemize} 
\end{frame} 


\section{Allouer de la memoire}

\begin{frame}[fragile=singleslide]{Quelques notions}
  \begin{itemize}       
  \item Addresses physiques: Addresses physique de la mémoire
  \item Addresses virtuelles: Addresses convertie par le MMU
  \item Addresses  logiques: Addresses  dans l'espace du  noyau mappée
    linéairement sur les addresse physiques
    \begin{itemize} 
    \item Elles pouvent être  converties en addresses physiques par un
      simple shifting.
    \item Les addresse logique sont des addresse virtuelles
    \item  Sur les  architecture  32bits, les  adresses logiques  sont
      placées entre \texttt{0xC0000000} (3Go) et \texttt{0xFFFFFFFF}
    \item Il est toutefois possible de modifier ce parametrage
    \item Il est possible de convertir une adresse logique en addresse
      physique avec la macro \c{__pa}
    \item ... et faire l'inverse avec la macro \c{__va}
    \end{itemize} 
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Quelques notions}
  \begin{itemize} 
  \item  Mémoire  basse (\emph{Low  Memory}):  Partie de  l'addressage
    virtuel contenant les addresses logiques. (voir \c{/proc/kallsyms}
    en root)
  \item Mémoire  haute (\emph{High Memory}): Le  reste de l'addressage
    virtuel
  \item \emph{Out Of Memory (OOM) killer}: Mécanisme déclenché lorsque
    le  système  ne peut  plus  founir de  mémoire.  Dans  ce cas,  un
    processus  est désignée  pour  être \emph{killé}.  Il s'agit  d'un
    algorithme heuristique
  \end{itemize}     
\end{frame} 
% Il existe aussi : phys_to_virt, virt_to_phys, page_to_virt, phys_to_page, page_to_phys, 
% pfn_to_page, page_to_pfn
% Le passage paddr -> pfn: (paddr) >> PAGE_SHIFT
% Le passage pfn -> paddr: (pfn) << PAGE_SHIFT

\begin{frame}[fragile=singleslide]{Les pages}
  Les pages sont l'unité de gestion du MMU. 
  \begin{itemize} 
  \item \c{PAGE_SIZE}  indique la  taille des page  sur l'architecture
    courante
  \item Une page fait 4 à 8Ko.
  \item \emph{Page Frame  Number (PFN)} Le numéro de  la page. Ce sont
    en fait les bit de poids fort des addresses.
  \item  Il  est  facile  de  convertir les  pages  en  \emph{pfn}  et
    inversement avec \c{page_to_pfn}  et \c{pfn_to_page} (correspond à
    \c{phys_addr >> PAGE_SHIFT} et \c{pfn << PAGE_SHIFT})
  \item Il est possible d'obtenir l'addresse virtuelle d'une page avec
    la  macro  \c{page_address}  (si  elle est  mappée  dans  l'espace
    d'addressage du noyau)
  \item ... l'inverse est possible avec \c{virt_to_page}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Les pages}
  \begin{itemize} 
  \item Il est possible d'allouer et de désallouer des pages avec:
    \begin{lstlisting} 
struct page *alloc_pages(unsigned int flags, unsigned int order);
struct page *alloc_page(unsigned int flags);
void __free_page(struct page *page);
void __free_pages(struct page *page, unsigned int order);
    \end{lstlisting} 
  \item Les \c{flags} sont décrit un peu plus loin
  \item  \c{order} indique  le nombre  de  pages à  allouer. Le  noyau
    alloue $2^{order}$ pages
  \item  \c{int  get_order(unsigned  long  size)}  retourne  \c{order}
    nécessaire pour avoir \c{size} octets de memoire
  \item Il  existe des  raccourcis pour allouer  une nouvelle  page et
    obtenir son addresse:
    \begin{lstlisting} 
unsigned long get_zeroed_page(int flags);
unsigned long __get_free_page(int flags);
unsigned long __get_free_pages(int flags, unsigned long order);
void free_page(unsigned long addr);
void free_pages(unsigned long addr, unsigned long order);
    \end{lstlisting} 
  \item Référence: \c{linux/gfp.h}, \c{/proc/meminfo}
  \item Il est  possible d'allouer des zones de  mémoires plus petites
    en utilisant le \c{slab} ou \c{vmalloc}
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{Le Slab}
  \begin{itemize} 
  \item  Le   slab  est  l'allocateur  de  mémoire   du  noyau.  C'est
    l'équivalent de l'allocateur de la libc.
  \item Il existe des alternatives telles que le Slub ou le Slob
  \item Il gère des \emph{pool} d'espace mémoire. 
  \item Il est possible d'obtenir  des informations sur l'état du slab
    en lisant le fichier \cmd{/proc/slabinfo}
  \item  Il est  possible d'allouer  et  de désallouer  des espace  de
    mémoire avec le Slab en utilisant:
    \begin{lstlisting} 
void *kmalloc(size_t size, gfp_t flags);
void kzalloc(size_t size, gfp_t flags);
void kzfree(const void *p);
void *kcalloc(size_t n, size_t size, gfp_t flags);
void kfree(const void *objp);
    \end{lstlisting} 
  \item On retrouve aussi l'équivalent de \c{realloc}:
    \begin{lstlisting} 
void *krealloc(const void *p, size_t new_size, gfp_t flags);
    \end{lstlisting} 
  \item Sauf mention contraire, le Slab retourne des addresse logiques
  \item Dans tous les cas, le Slab retourne de la mémoire physiquement
    contigüe
  \item Référence: \c{linux/slab.h}
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{Création de \emph{pool} dans le Slab}
  Si vous avez  de grande quantité d'objets identiques  à gérer, ou si
  vous avez des besoins spécifique, vous pouvez créer un pool
  spécialement pour vos besoins.\\[2ex]

  Le cas échént, il est  même possible d'utiiser vos propres fonctions
  d'allocation:
  \begin{lstlisting} 
mempool_t *mempool_create(int min_nr, mempool_alloc_t *alloc_fn, mempool_free_t *free_fn, void *data);
void mempool_destroy(mempool_t *pool);
  \end{lstlisting} 
  Vous pouvez garder la politique d'allocation par défaut en
  utilisant:
  \begin{lstlisting} 
void *mempool_alloc(mempool_t *pool, int gfp_mask);
void mempool_free(void *element, mempool_t *pool);
  \end{lstlisting} 
  Référence: \c{linux/mempool.h}, \c{/proc/slabinfo}
\end{frame}

\begin{frame}[fragile=singleslide]{Options d'allocation}
  Elles permettent de spécifier  des contraintes sur l'allocateur. Les
  plus courantes sont:
  \begin{itemize} 
  \item \c{GFP_KERNEL}: Standard
  \item  \c{GFP_USER}: De  la  mémoire  destinée à  être  donnée à  un
    processus utilisateur.  Elle est alors bien  séparé pages allouées
    pour le noyau.
  \item \c{GFP_HIGHUSER}:  Indique en plus que  l'allocation doit être
    faite dans la mémoire haute
  \item  \c{GFP_ATOMIC}:  L'allocateur  ne  peux  pas  bloquer  durant
    l'allocation.      Permet     d'être     utilisé      dans     des
    interruptions. Utilise  le pool d'allocation d'urgence.  Ne pas en
    abuser.
  \item \c{GFP_DMA}:  Retourne un bloc contenu  dans l'espace physique
    utilisable par les DMA
  \item Référence: \c{linux/gfp.h}
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{vmalloc}
  \begin{itemize} 
  \item Il est possible d'allouer de la mémoire non-contigüe avec
    \c{vmalloc}:
    \begin{lstlisting} 
void *vmalloc(unsigned long size);
void *vzalloc(unsigned long size);
void vfree(void *addr);
    \end{lstlisting} 
  \item Alloue dans la mémoire haute
  \item ...  ainsi la mémoire allouée  peut être non  contigüe dans la
    mémoire physique
  \item  Il  est ainsi  possible  d'allouer  d'importante quantité  de
    mémoire.
  \item Référence: \c{linux/vmalloc.h}, \c{mm/vmalloc.c}, \c{/proc/vmallocinfo}
  \end{itemize} 
\end{frame}

\section{La MMU}

\begin{frame}[fragile=singleslide]{La mémoire des processus}
  \begin{itemize} 
  \item La variable \c{current} pointe sur le processus courant
  \item Chaque processus possède une table de mapping mémoire
  \item Le mapping du processus courant se trouve dasn \c{current->mm}
    \begin{itemize} 
    \item  \c{current->mm->rb_tree} contient des  \emph{virtual memory
        area (vma)} sous la forme d'un arbre rouge-noir
    \item     Il    est     possible     d'utiliser    la     fonction
      \c{find_vma(mm, addr)} pour retrouver une VMA
    \item  allouer de  la  memoire consiste  à  allouer une  structure
      \c{vm_area_struct} et l'ajouter dans l'arbre rouge-noir
    \item Le  noyau parle  ensuite \emph{to pin}  une page  en mémoire
      lorsque celle-ci doit être réellement allouée
    \end{itemize} 
  \item Il est possible d'obtenir les mapping d'un processus en lisant
    les   fichier   \file{/proc/<PID>/map},   \file{/proc/<PID>/smap},
    \file{/proc/<PID>/pagemap}
  \item         Référence:        \file{Documentation/vm/pagemap.txt},
    \file{Documentation/filesystems/proc.txt}, \file{linux/mm.h}
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{Mapper des addresse physiques}
  Parmi les  fonctions les plus utiles,  \c{remap_pfn_range} permet de
  mapper des  addresses physique dans un espace  utilisateur. Elle est
  particulièrement utile pour implémentér l'appel \c{mmap}:
  \begin{lstlisting} 
int remap_pfn_range(
  struct vm_area_struct *vma,
  unsigned long addr, 
  unsigned long pfn,  
  unsigned long size, 
  pgprot_t flags);    
  \end{lstlisting} 
  \begin{itemize}
  \item  \c{vma} Espace  d'addressage virtuel  dans lequel  le mapping
    doit s'effectuer. Dans le cadre de mmap, fournie par le kernel.
  \item \c{addr} L'addresse à l'intérieur de \c{vma} (=offset)
  \item \c{pfn} La page physique à mapper     
  \item \c{size} Taille de l'interval à mapper 
  \item \c{flags} Flags éventuels (reprendre \c{vma->vm_page_prot})
  \end{itemize} 

  Il     est    aussi     possible     de    surcharger     l'attribut
  \c{vm_operations_struct *  vm_ops} de la  \c{vm_area_struct} afin de
  gérer soit même les différentes exceptions. Peut-être utile pour le
  développement de certains drivers (good luck) \\[2ex]

  Référence: \file{linux/mm.h}
\end{frame} 

\begin{frame}[fragile=singleslide]{Sparse}
  \begin{itemize} 
  \item Sparse est un outils spécifique au noyau
  \item Sparse parse le code et interprète certain attribut on définit
    lors de la compilation avec \cmd{gcc}
  \item \c{bitwise} indique que deux  types ne peuvent pas être castés
    (exemple: \c{phys_addr_t} et \c{long unsigned})
  \item  \c{address_space(NUM)} précise  le domaine  d'un  pointeur et
    empêche les  pointeurs de différent domaines  d'être affecté entre
    eux:
    \begin{itemize}
    \item \c{address_space(0)} Kernel
    \item \c{address_space(1)} User
    \item \c{address_space(2)} MMIO
    \end{itemize} 
  \item Lancer  vos compilation  avec l'option \cmd{C=1}  pour activer
    Sparse
  \item Référence: \file{linux/compiler.h}, \emph{sparse(1)}
  \end{itemize} 
\end{frame} 

\section{Les interruptions}

\subsection{Allouer des interruptions}

\begin{frame}[fragile=singleslide]{Interruptions}
  Pour demander la gestion d'une interruption:
  \begin{lstlisting}  
int request_irq(
  unsigned int irq, 
  irq_handler_t handler, 
  unsigned long flags, 
  const char *devname, 
  void *dev_id)
  \end{lstlisting} 
  \begin{itemize} 
  \item \c{irq}: Le numéro de l'IRQ
  \item \c{handler} La fonction à appeller.
  \item \c{flags} Principalement : 
    \begin{itemize} 
    \item \c{IRQF_SHARED} : L'interruption peut être partagé
    \end{itemize} 
  \item \c{devname}: Un descriptif pour \c{/proc/interrupts}
  \item  \c{dev_id}:   Pointeur  qui   sera  passé  en   paramètre  de
    \c{handler}. On utilise généralement un pointeur sur une structure
    decrivant l'instance du device. Ce pointeur à aussi son importance
    lors de la libération de l'interruption.
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Interruptions}
  \begin{itemize} 
  \item  Il   est  possible  d'obtenir  la   liste  des  interruptions
    enregistrées dans \file{/proc/interrupts}
  \end{itemize} 
  On libère l'interruption avec:
  \begin{lstlisting} 
void free_irq(unsigned int irq, void *dev_id)
  \end{lstlisting} 
  \begin{itemize} 
  \item \c{irq}: Numéro d'irq
  \item \c{dev_id}:  Instance à  supprimer. \c{dev_id} doit  donc être
    unique pour chaque IRQ
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Le PIC}
  Une  fois  allouée, il  est  possible  de  demander au  système  (au
  \emph{Programmable Interrupts  Controller (PIC)} en  fait) d'activer
  ou non l'interruption avec :
  \begin{lstlisting}
void enable_irq(unsigned int irq)
void disable_irq(unsigned int irq)
  \end{lstlisting} 

  Note:  Les  PIC  sont  des  périphériques  comme  les  autres.  Nous
  n'expliquons  pas spécifiquement  ici comment  développer  un driver
  pour un PIC.

  Référence:  \c{linux/interrupts.h}
\end{frame}

\begin{frame}[fragile=singleslide]{Les handlers d'interruption}
  Les handler d'interruption:
  \begin{itemize} 
  \item Il est de type \c{irqreturn_t (*)(int irq, void *dev_id)}
  \item Il doit retourner (\c{irqreturn_t})
    \begin{itemize} 
    \item  \c{IRQ_HANDLED} si l'interruption a bien été gérée
    \item \c{IRQ_NONE}  ... sinon. L'interruption est  alors passée au
      handler enregistré suivant si l'interruption est partagée
    \end{itemize} 
  \item Il doit acquiter l'interruption sur le périphérique
  \item Il ne doit pas être bloquant: 
    \begin{itemize} 
    \item pas de \c{wait_event}
    \item pas de \c{sleep}
    \item allocation de mémoire avec \c{GFP_ATOMIC}
    \item  attention aux sous-fonctions,  vérifier qu'elles  sont bien
      \emph{interrupt compliant}
    \end{itemize}
  \item  Le   maximum  de  traitement   doit  être  reporté   dans  le
    \emph{Bottom Half (bh)}
  \end{itemize}  
\end{frame} 

\subsection{Les Softirq}

\begin{frame}[fragile=singleslide]{Softirq}
  \begin{itemize} 
  \item   Les  softirqs   sont  executés   dans   l'environnement  des
    interruptions mais alors que les interruptions sont activées
  \item Elle  n'empêchent pas le déclenchement  des interruptions mais
    ne sont pas schedulés avec les tâches
  \item   Par  conséquent,   quasiment  les   mêmes  règles   que  les
    interruptions s'appliquent
  \item Les Softirq sont réservés aux tâche demandant une fréquence de
    traitement  importante.  Les  developpeurs  du kernel  gardent  le
    nombre de Softirq en quantité limitée:
    \begin{lstlisting}[language=sh]
HI_SOFTIRQ,         BLOCK_IOPOLL_SOFTIRQ,
TIMER_SOFTIRQ,      TASKLET_SOFTIRQ,
NET_TX_SOFTIRQ,     SCHED_SOFTIRQ,
NET_RX_SOFTIRQ,     HRTIMER_SOFTIRQ,
BLOCK_SOFTIRQ,      RCU_SOFTIRQ,
    \end{lstlisting} 
  \item Les Softirq HI et Tasklet sont des multiplexeurs permettant
    d'éxécuter d'autres tâches
  \item Référence: \c{linux/interrupts.h}
  \end{itemize} 
\end{frame}

\begin{frame}[fragile=singleslide]{Tasklets}
  \begin{itemize} 
  \item Executés par les Softirq HI et Tasklet
  \item  HI est  executé  avec la  priorité  la plus  haute parmi  les
    Softirq, alors que les Tasklets ont quasiement la priorité la plus
    basse
  \item Pour initialiser et désenregistrer un tasklet:
    \begin{lstlisting} 
DECLARE_TASKLET(name, void (*func)(unsigned long), unsigned long data);
void tasklet_init(struct tasklet_struct *t, void (*func)(unsigned long), unsigned long data);
void tasklet_kill(struct tasklet_struct *t);
    \end{lstlisting} 
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Tasklets}
  \begin{itemize} 
  \item Pour demander l'éxecution d'un Tasklet (dans le SoftIRQ Tasklet et dans le SoftIRQ HI)
    \begin{lstlisting} 
void tasklet_schedule(struct tasklet_struct  *t)
void tasklet_hi_schedule(struct tasklet_struct *t)
    \end{lstlisting} 
  \item Si  la tasklet était deja  prévue pour être  éxecutée, elle ne
    sera executé qu'une fois.
  \item  Si  la tasklet  est  déjà  en  cours d'éxecution,  elle  sera
    réexécutée (mais pas simultannément, même sur un SMP).
  \item Référence: \c{linux/interrupts.h}
  \end{itemize}
\end{frame} 

\begin{frame}[fragile=singleslide]{Les kthreads}
  \begin{itemize}
  \item Equivalent à des threads en userspace
  \item Créer une kthreads:
    \begin{lstlisting} 
struct task_struct *kthread_create(int (*threadfn)(void *data), void *data, const char namefmt[], ...)
    \end{lstlisting} 
  \item  Marquer   la  tâche   comme  devant  être   être  ordonnancée
    (Fonctionne avec toute les tâches, pas spécifique aux kthreads)
    \begin{lstlisting} 
wake_up_process(struct task_struct *k)
    \end{lstlisting} 
  \item Il est possible de faire \c{kthread_create} et \c{wake_up} en
    un seul appel:
    \begin{lstlisting} 
struct task_struct *kthread_run(int (*threadfn)(void *data), void *data, const char namefmt[], ...)
    \end{lstlisting}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Les kthreads}
  \begin{itemize}
  \item Affecter une kthread à un CPU
    \begin{lstlisting}
void kthread_bind(struct task_struct *k, unsigned int cpu)
    \end{lstlisting} 
  \item Tuer une kthread:
    \begin{lstlisting} 
int kthread_stop(struct task_struct *k)
    \end{lstlisting} 
  \item  Ne pas  trop abuser  des kthreads.  Les  calculs s'effectuent
    normalement dans les SoftIRQ et surtout dans les appel système des
    processus.  Le cas échéant,  préférez l'utilisation  des Workqueue
    génériques. Enfin,  posez-vous la  question si l'action  doit être
    effectuée dans le noyau ou dans l'espace utilisateur
  \item Référence: \c{linux/kthread.h}
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{Workqueues}
  \begin{itemize} 
  \item Mécanisme général pour repousser un calcul
  \item Permet d'ordonnancer des des tâches dans une kthread
  \item  Exemple d'utilisation  des  Workqueues: flush  des cache  des
    disques, défragmentation en background, etc...
  \item  \c{INIT_WORK(work,  func)} permet  de  déclarer une  nouvelle
    structure \c{work} executant \c{func}
  \item \c{int schedule_work(struct work_struct *work)} permet de
    demander l'éxecution de \c{work}
  \item  \c{int schedule_work_on(int  cpu, struct  work_struct *work)}
    spécifie un CPU particulier surlequel le \c{work} doit s'éxecuter
  \item
    \c{int schedule_delayed_work(struct delayed_work *work, unsigned long delay)}
    démarre \c{work} après un certain délais. Permet de faire des
    tâches periodiques.
  \item \c{bool cancel_delayed_work(struct delayed_work *work)} Annule
    une tâche délayée
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Workqueues}
  \begin{itemize} 
  \item  Il  est possible  d'utiliser  d'autre  workqueue (=  d'autres
    kthreads) que celle de \c{schedule_work}
  \item
    \c{int queue_work(struct workqueue_struct *wq, struct work_struct *work)}
    permet de demander l'éxecution de work en spécifiant la workqueue.
  \item  Il est  aussi possible  de créer  ses propres  workqueue avec
    \c{alloc_workqueue(name, flags, max_active)}
  \item Référence: \c{linux/workqueue.h}
  \end{itemize}
\end{frame}

\section{Les Wait Queues}

  % Wait_event
\begin{frame}[fragile=singleslide]{Les Wait Queues}
  \begin{itemize} 
  \item Permet d'attendre de manière passive un évènement. 
  \item Peut-être utilisé
    dans le contexte d'une tâche ou dans une kthread.
  \item  Cela permet  de  faire  passer la  tâche  associée de  l'état
    \emph{run} à l'état \emph{wait}
  \item Fonctionne de manière  similaire à des \c{pthread_cond} ou des
    \c{rt_event} sous Xenomai ou les \c{OSFlags} sous µC/OS-II
  \item Pour déclarer:
    \begin{itemize} 
    \item \c{DECLARE_WAIT_QUEUE_HEAD(my_queue)} : initialisation lors de
      la déclaration
    \item
      \c{wait_queue_head_t  my_queue; init_waitqueue_head(&my_queue)}:
      Déclaration et initialisation séparés
    \end{itemize} 
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Les Wait Queues}
  \begin{itemize} 
  \item Pour attendre un évènement:
    \begin{itemize} 
    \item Attend  un evenement sur la  queue ET que  la condition soit
      vérifiée
      \begin{lstlisting} 
void wait_event(queue, condition);
      \end{lstlisting} 
    \item  Idem mais  retourne une  erreur  si executé  dans un  appel
      system et le processus est tué avec \c{SIGKILL}
      \begin{lstlisting} 
int wait_event_killable(queue,  condition);
      \end{lstlisting} 
    \item  Idem mais  retourne une  erreur  si executé  dans un  appel
      system et le processus recoit un signal
      \begin{lstlisting} 
int  wait_event_interruptible(queue, condition);
      \end{lstlisting} 
    \item   Idem
      \c{wait_event} mais avec un timeout
      \begin{lstlisting} 
void wait_event_timeout(queue, condition);
      \end{lstlisting} 
    \item \c{wait_event_timeout} + \c{wait_event_interruptible}:
      \begin{lstlisting} 
void  wait_event_tinterruptible_imeout(queue, condition);
      \end{lstlisting} 
    \end{itemize} 
  \item Pour réveiller les tâches en attentes
    \begin{itemize} 
    \item Réveil tous les processus en attente sur la queue
      \begin{lstlisting} 
wait_up(queue); 
      \end{lstlisting} 
    \item Idem mais, seulement les interruptibles
      \begin{lstlisting}
wait_up_interruptible(queue);
      \end{lstlisting} 
    \end{itemize}
  \end{itemize}  
\end{frame} 

\section{Les DMA}
 
\begin{frame}[fragile=singleslide]{\emph{Coherent mapping}}
  \begin{itemize}
  \item Gère un mapping ``cohérent'' accessible depuis le device et le
    CPU
    \begin{lstlisting} 
void *dma_alloc_coherent(
  struct device *dev, /* Device sur lequel est mappé le DMA. Fourni par le framework */
  size_t size,        /* Taille du mapping */
  dma_addr_t *handle, /* Adresse physique à fournir au device */
  gfp_t gfp)           /* Flags habituels */
    \end{lstlisting} 
  \item  \c{dma_alloc_coherent} retourne  une addresse  virtuelle pour
    accéder au mapping par le CPU.
  \item La liberation du buffer se fait par:
    \begin{lstlisting} 
void dma_free_coherent(struct device *dev, size_t size, void *cpuaddr, dma_handle_t bus_addr);
    \end{lstlisting} 
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{\emph{Streaming mapping}}
  \begin{itemize} 
  \item  Dans ce  mode, le  driver  doit allouer  lui-même la  mémoire
    (utilisation de \c{GFP_DMA}).
  \item Il faut configurer le cache  du CPU que la zone mémoire puisse
    être utilisé pour un DMA:
    \begin{lstlisting} 
dma_addr_t dma_map_single(struct device *dev, void *buffer, size_t size, enum dma_data_direction direction);
    \end{lstlisting} 
  \item \c{direction} peut être \c{DMA_TO_DEVICE},
    \c{DMA_FROM_DEVICE}, \c{DMA_BIDIRECTIONAL}, \c{DMA_NONE}
  \item Le cache  n'est pas cohérent. Pour accèder  au buffer, il faut
    appeller:
    \begin{lstlisting} 
void dma_unmap_single(struct device *dev, dma_addr_t bus_addr, size_t size, enum dma_data_direction direction)
    \end{lstlisting} 
  \item Cet appel doit être fait après que le périphérique ait terminé
    ces accès au buffer
  \item  Le  \emph{streaming  mapping}  permet des  optimisations  que
    \emph{coherent mapping} ne permet pas
  \end{itemize}
\end{frame} 

\section{Les structures de données}

\subsection{Les listes}

  % Structures
  %    list
\begin{frame}[fragile=singleslide]{Les listes}
  \begin{itemize} 
  \item Implémentation assez singulière de listes génériques en C. 
  \item  utilisation  de  la  macro  \c{container_of}  qui  permet  de
    retourner  un  pointeur   sur  l'objet  contenant  en  connaissant
    l'addresse d'un attribut et et le type:
    \begin{lstlisting} 
#define container_of(ptr, type, member) ({ \ 
   const typeof( ((type *)0)->member ) *__mptr = (ptr); \
   (type *)( (char *)__mptr - offsetof(type,member) );})
    \end{lstlisting} 
  \item Pour déclarer une liste: 
    \begin{itemize}
    \item Declarer un type pour les noeuds de sa liste
    \item Ajouter un attribut de type \c{struct list_head} à son type
    \end{itemize} 
  \item   Une   liste   vide    est   alors   composé   d'une   simple
    \c{struct list_head} à déclarer avec \c{LIST_HEAD(my_var)}
  \item Pour  les fonction d'ajout, suppression, etc...  tout est géré
    avec les \c{list_head}
  \item  Pour accèder  au données  liées à  un \c{list_head},  il faut
    utiliser la  macro \c{list_entry} (qui  est en fait la  même chose
    que \c{container_of})
  \item Référence: \file{linux/list.h}
  \end{itemize}  
\end{frame}

\begin{frame}[fragile=singleslide]{Les listes}
  Exemple: 
  \note[item]{En faire un module}
    \begin{lstlisting}
#include <linux/list.h>
stuct my_node_t {
  struct list_head node;
  /* other attributes */
}
void f() {
   LIST_HEAD(my_list);
   struct my_node_t new_node; 
   struct my_node_t *i; 
   printf("%d\n", list_empty(my_list));
   list_add(&new_node->node, &my_list);
   printf("%d\n", list_size(my_list));
   list_for_each_entry(i, &my_list, node) {
   }
} 
    \end{lstlisting} 
\end{frame} 

%    rbtree
% Existe aussi les radix tree (aka priotree)
\begin{frame}[fragile=singleslide]{Les arbres}
  \begin{itemize} 
  \item  Il existe  deux implémentations  principales d'arbre  dans le
    noyau
  \item Les \emph{rbtree} (arbres rouges-noirs)
  \item Fonctionnent  aussi à base de  \c{container_of} mais nécessite
    une plus grande part de personnalisation que les listes.
  \item  En particulier,  nécessite l'implémentation  des  fonction de
    recherche et d'ajout.
  \item  Cette architecture permet  de définir  sa propre  fonction de
    comparaison sans impacte sur  les performance et en maintenant une
    certaine généricité
  \item       Références:      \file{Documentation/rbtree.txt}      et
    \file{linux/rbtree.h}
  \item  Les \emph{radix  priority  search tree}  (arbres préfixes  ou
    \c{prio_tree})
  \item Uniquement utilisé pour référencer les structures \c{vma}
  \item      Références:     \file{Documentation/prio\_tree.txt}     et
    \file{linux/prio\_tree.h}
  \end{itemize} 
\end{frame} 


\section{Mecanismes de synchronisation}

\begin{frame}[fragile=singleslide]{Les fifo}
  \begin{itemize} 
  \item Appellé aussi \emph{Buffer Circulaire}
  \item L'une des structure les plus utilisée dans le noyau
  \item Permet la communication avec les interruptions (pas de pause
    lors des accès) et entre les processus
  \item Pendant longtemps, chaque driver avait son implémentation de
    fifo
  \item    Il   existait   un    début   d'interface    commune   dans
    \file{linux/circ\_buf.h}
  \item Il existe maintenant une implémentation de référence:
    \emph{kfifo}
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{kfifo}
  \begin{itemize}
  \item Déclarer et initialiser une kfifo: 
    \begin{lstlisting} 
DEFINE_KFIFO(fifo, type, size)
    \end{lstlisting} 
  \item \c{fifo}: Nom de la fifo
  \item \c{type}: Type des objets à contenir
  \item \c{size}; Taille de la fifo
  \item Pour pousser, tirer et lire des éléments:
    \begin{lstlisting} 
int kfifo_put(fifo, val) 
int kfifo_get(fifo, val)
int kfifo_peek(fifo, val)
    \end{lstlisting} 
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{kfifo}
  \begin{itemize}
  \item Pleins d'autres fonctions utiles:
    \begin{lstlisting}
kfifo_recsize(fifo)
kfifo_reset(fifo) 
kfifo_size(fifo)  
kfifo_len(fifo)
kfifo_is_full(fifo)
kfifo_is_empty(fifo)
    \end{lstlisting} 
  \item Il est possible de coupler une kfifo avec \c{wait_queue}
  \item Il est  possible de déclarer une kfifo  avec un espace mémoire
    déporté  de la  structure  et ainsi  utiliser  des espace  mémoire
    spéciaux.
  \end{itemize} 
\end{frame} 

  %    Désactivation de la concurrence
\begin{frame}{Mutex}
  Précaution classique à l'utilisation des sections critiques:
  \begin{itemize}
  \item Acquérir le mutex le plus tard possible, Relacher le plus tôt
  \item Etudier la granularité nécessaires aux sections critiques
  \item   Attention  aux   bug  classiques:   latences,   dead  locks,
    inversement de priorités
  \end{itemize} 
\end{frame}

\begin{frame}[fragile=singleslide]{Mutex}
  Méthodes assez classiques des mutex:
  \begin{itemize}
  \item Déclarer et initialiser un mutex:
    \begin{lstlisting} 
DEFINE_MUTEX(name);
void mutex_init(struct *mutex);
    \end{lstlisting} 
  \item  Acquierrir   le  mutex.  Attention,  si   appellé  depuis  un
    processus,     celui-ci     ne      peut     plus     être     tué
    \begin{lstlisting} 
mutex_lock(struct mutex *lock);
    \end{lstlisting} 
  \item Idem, mais le processus peut-être tué
    \begin{lstlisting} 
mutex_lock_killable(struct  mutex  *lock);
    \end{lstlisting} 
  \item Idem, mais le processus peut être interrompu avec un signal
    \begin{lstlisting} 
mutex_lock_interruptible(struct mutex *lock);
    \end{lstlisting} 
  \item Idem, mais retourne immédiatement si le mutex est déjà locké
    \begin{lstlisting} 
mutex_trylock(struct  mutex  *lock); 
    \end{lstlisting} 
  \item Retourne 1 si le mutex est locké
    \begin{lstlisting} 
mutex_is_locked(struct  mutex *lock);
    \end{lstlisting} 
  \item  Unlock le mutex
    \begin{lstlisting} 
mutex_unlock(struct mutex *lock);
    \end{lstlisting} 
  \end{itemize}
  Réfrence: \c{linux/mutex.h}
\end{frame} 

  %    semaphore
  %    rw_semaphore
\begin{frame}[fragile=singleslide]{Autre mécanismes}
Dans la même branche, le noyau propose aussi:
\begin{itemize} 
\item Des sémaphores (référence: \file{linux/semaphore.h})
\item Des \emph{Read-Write Lock} (référence: \file{linux/rw\_semaphore.h})
\item  Mutex avec protocole  d'héritage de  prioritée et  détection de
  deadlock           (aka           \c{rt_mutex})          (référence:
  \file{Documentation/rt-mutex-design.txt}, \file{linux/rtmutex.h})
\item  Les   \c{rtmutex}  peuvent  être  utilisé   par  la  \c{libpthread}
  (référence:                         \file{Documentation/pi-futex.txt}
  \file{Documentation/rt-mutex.txt})
\end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{Désactivation des interruption et de la préemption}
  \begin{itemize} 
  \item  Lors de  certains  accès, les  mécanismes  de protections  de
    ressources inter-tâche ne sont plus suffisants.
  \item   Cela   peut  concerner   des   accès   concurant  avec   des
    interruptions.
  \item  Il  est alors  nécessaire  de  désactiver temporairement  les
    interruptions afin de garantir que l'on ne sera pas interrompu.
  \item   Ces fonctions sont à utiliser avec parcimonie:
    \begin{itemize} 
    \item  Sauve/restore  l'état  des  interuptions dans/de  flags  et
      désactive les interruptions:
      \begin{lstlisting} 
local_irq_save(unsigned long flags);
local_irq_restore(unsigned long flags);
      \end{lstlisting} 
    \item  Désactive/Active  les  interruptions  (à  priori,  toujours
      utiliser les versions \c{_save} et \c{_restore})
      \begin{lstlisting} 
local_irq_disable();
local_irq_enable();
      \end{lstlisting} 
    \item  Retourne  vrai  si  les  interruption  du  CPU  local  sont
      désactivées:
      \begin{lstlisting} 
local_irq_disabled();
      \end{lstlisting} 
    \item Désactive/Réactive les softirq (bottom halves):
      \begin{lstlisting} 
local_bh_disable();
local_bh_enable();
      \end{lstlisting} 
    \item Désactive/Réactive la préemption
      \begin{lstlisting} 
preempt_disable();
preempt_enable();
      \end{lstlisting} 
    \end{itemize} 
  \end{itemize} 
\end{frame} 

\begin{frame}[fragile=singleslide]{Spin Lock}
  Dans certains cas, une tâche peut avoir besoin d'un accès exclusif à
  une ressource  potentiellement utilisée dans  une interruption. Dans
  ca cas,  il est  necessaire de désactiver  les interruption  lors de
  l'accès à la ressource.   Néanmoins, l'interruption peut se produire
  sur un  autre CPU.   Il est alors  nécessaire de se  protèger contre
  cette éventualité
  \begin{itemize} 
  \item Il s'agit d'une attente active sur une section critique
  \item Ne traite pas les  problème de concurence mais de parallèlisme
    uniquement. Par conséquent, uniquement en environnement SMP
  \item   Principalement  utilisé   lors  de   en  complément   de  la
    désactivation des interruption
  \item La préemption est aussi désactivé durant un spinlock
  \item  Le  noyau propose  aussi  des  \emph{Read  Write Spinlock}  :
    \c{rwlock_t} (Référence \file{linux/rwlock.h})
  \end{itemize}  
\end{frame}

\begin{frame}[fragile=singleslide]{Spin Lock}
  API:
  \begin{itemize}
  \item Déclarer et initialiser un spin lock:
    \begin{lstlisting} 
DEFINE_SPINLOCK(lock);
spin_lock_init(spinlock_t *lock);
    \end{lstlisting} 
  \item Idem que les fonction \c{mutex_*}:
    \begin{lstlisting} 
spin_lock(spinlock_t *lock);
spin_trylock(spinlock_t *lock);
spin_unlock(spinlock_t *lock);
    \end{lstlisting} 
  \item Lock et désactive/réactive les interruptions sur le processeur
    courant.  Les flags contiennent l'état du masque d'interruption:
    \begin{lstlisting} 
spin_lock_irqsave(spinlock_t *lock, unsigned long flags);
spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);
    \end{lstlisting} 
  \item Spinlock et désactive/réactive les softirq:
    \begin{lstlisting} 
spin_lock_bh(spinlock_t *lock);
spin_unlock_bh(spinlock_t *lock);
    \end{lstlisting} 
  \end{itemize}
  Référence :  \file{linux/spinlock.h}
\end{frame}

% Lister :
  %    operations atomiques
  %    RCU

\begin{frame}[fragile=singleslide]{Read-Copy-Update (RCU)}
  Type d'algorithme non bloquant:
  \begin{itemize} 
  \item La lecture n'est pas bloquante
  \item On note le nombre de lecteurs
  \item Les modification s'effectuent sur une copie de l'objet
  \item Les lecture suivante se font sur la nouvelle version de l'objet
  \item Lorsque  le dernier lecteur  a terminé, l'objet  d'origine est
    détruit. Seul subsiste la nouvelle version.
  \item  Les RCU sont un design d'architecture. Les RCU ne possède que peu d'API pouvant être réutilisé.
  \item Référence \file{Documentation/RCU/whatisRCU.txt} \file{Documentation/RCU/*} 
  \end{itemize} 
\end{frame}

\begin{frame}[fragile]{Exemple : Manipulation de listes} 
  \begin{center}
    \begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{colBasic},commentstyle=\scriptsize\itshape\color{colComments},numbers=none]
typedef struct {
   struct a_t a;
   int count_usage = 0;
   bool obsolete = false;
} rcu_t;
rcu_t *a = malloc(sizeof(rcu_t)); 
    \end{lstlisting}
  \end{center}
  \begin{columns}
    \begin{column}{5cm}
      \begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{colBasic},commentstyle=\scriptsize\itshape\color{colComments},numbers=none]
void read_a() {
  // lock:
  rcu_t *ptr = a;
  ptr->count_usage++;
  // do something with ptr;
  // unlock:
  ptr->count_usage--;
  if (ptr->obsolete && !ptr->count_usage)
    free(ptr);
}
      \end{lstlisting}
    \end{column}
    \begin{column}{5cm}
      \begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{colBasic},commentstyle=\scriptsize\itshape\color{colComments},numbers=none]
void write_a() { 
   struct rcu_t *a3 = a;
   struct rcu_t *a2 = malloc(sizeof(rcu_t));
   memcpy(a2, a);
   // modify a2;   
   a = a2;  
   a3->obsolete = true;
   if (!a3->count_usage)
      free(ptr);
}
      \end{lstlisting} 
    \end{column}
  \end{columns}
\end{frame} 

  %    barrier
\begin{frame}[fragile=singleslide]{les barrières mémoire}
  \begin{itemize} 
  \item  Le  compilateur  et  le  CPU peuvent  optimiser  du  code  en
    réordonnancant les instructions.
  \item Le compilateur et le  CPU ne réordonnance que les instructions
    indépendantes (donc, a priori, sans danger)
  \item Ce comportement peut  nénamoins introduire des erreurs sur les
    système SMP ou lors d'accès à certains périphériques.
  \item  Il est  assez complexe  de savoir  ou doivent  se  placer les
    barrières. Elle interviennent néanmoins dans un certains nombre de
    structures de données ou d'algorithme
  \item Les  barrière sont implémentées en  utilisant des instructions
    assembleur particulières
  \item \c{barrier()}  est un barrière  pour le compiler.   Toutes les
    instruction   avant   la  barrière   seront   placées  avant   les
    instructions apès la barrière
  \item Toutes les barrières  CPU impliquent une barrière compiler. Du
    coup \c{barrier()} est peu utilisé.
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{les barrières mémoire}
  \begin{itemize} 
  \item Utilisation de barrières :
    \begin{itemize}
    \item  \c{mmiowb()}  Empêche  le  réordonnancement  des  accès  en
      écriture à la mémoire mappée sur IO
    \item \c{rmb()} Barrière en  lecture. Toutes les lecture demandées
      avant la barrière sont terminée avant \c{rmb()} et aucun lecture
      demandées après la barrière n'est commencée avant \c{rmb()}
    \item \c{wmb()} Barrière en écriture
    \item \c{mb()} Lecture et ecriture
    \item   \c{smp_wmb()},  \c{smp_rmb()}   et  \c{smp_mb()}   ont  un
      comportement  identique,  mais  ne  sont présentent  que  si  le
      système est compilé en SMP
    \item Il existe d'autre types de barrières très spécifiques
    \end{itemize} 
  \item  Tous  les  mécanismes  de protections  de  ressources  partagé
    contiennent  déjà  des barrières  correctement  placées (ca  tombe
    bien, c'est la que c'est le plus complexe)
   
  \item Référence : \file{Documentation/memory-barriers.txt}
  \end{itemize} 
\end{frame} 
